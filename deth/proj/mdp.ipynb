{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Generic MDP Code\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cfd6b5e866cf9c9"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "\n",
    "class MDP:\n",
    "    def __init__(self, states, terminal_states, transitions, current_state=None, slippery_factor = 0.8, is_slippery = False, cost_of_living = 0.01 ):\n",
    "        self.states = states\n",
    "        self.terminal_states = terminal_states\n",
    "        self.actions = {state: list(action) for state, action in transitions.items()}\n",
    "        self.transitions = transitions\n",
    "        self.observation_space = len(states)\n",
    "        self.action_space = len(self.actions)\n",
    "        self.is_slippery = is_slippery\n",
    "        self.slippery_factor = slippery_factor\n",
    "        self.cost_of_living = cost_of_living\n",
    "        if current_state is None:\n",
    "            self.current_state = random.choice([s for s in states if s not in self.terminal_states])\n",
    "        else:\n",
    "            self.current_state = current_state\n",
    "\n",
    "    def reset(self):\n",
    "        available_states = [state for state in self.states if state not in self.terminal_states]\n",
    "        self.current_state = random.choice(available_states)\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        random_number_generator = np.random.default_rng()\n",
    "        if self.current_state in self.terminal_states:\n",
    "            raise Exception(\"Already in a terminal state\")\n",
    "        if action not in self.get_available_actions():\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        if self.is_slippery and random_number_generator.random() < self.slippery_factor:\n",
    "            action = random.choice(self.get_available_actions())\n",
    "            print(f\"Slipped\")\n",
    "\n",
    "        outcomes = self.transitions[self.current_state][action]\n",
    "        \n",
    "        if not outcomes:\n",
    "            print(f\"No transitions available from this state({self.current_state}).\")\n",
    "            self.current_state = None  \n",
    "            return self.current_state, 0, True\n",
    "\n",
    "        possible_states = list(outcomes.keys())\n",
    "        probabilities = [outcomes[state][0] for state in possible_states]\n",
    "\n",
    "        next_state = random.choices(possible_states, weights=probabilities)[0]\n",
    "        \n",
    "        reward = outcomes[next_state][1] - self.cost_of_living\n",
    "\n",
    "        print(f\"{current_state} -> {action} -> {next_state} | Reward: {reward}\")\n",
    "        \n",
    "        self.current_state = next_state\n",
    "        \n",
    "        done = self.current_state in self.terminal_states or not self.get_available_actions()\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def get_available_actions(self):\n",
    "        return self.actions[self.current_state]\n",
    "\n",
    "    def get_possible_next_states(self):\n",
    "        possible_states = set()\n",
    "        for action in self.actions[self.current_state]:\n",
    "            outcomes = self.transitions[self.current_state][action].keys()\n",
    "            possible_states.update(outcomes)\n",
    "        return list(possible_states)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T12:56:54.231587Z",
     "start_time": "2024-05-15T12:56:54.181873Z"
    }
   },
   "id": "2b0aad2f577a93a3",
   "execution_count": 240,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assignment 1.3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c4b4b3db222e7b2"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "states1_3 = [\n",
    "    'S0',\n",
    "    'S1',\n",
    "    'S2'\n",
    "]\n",
    "\n",
    "transitions1_3 = {\n",
    "    'S0': {\n",
    "        'a0': {'S0': [0.5, 0], 'S2': [0.5, 0]},\n",
    "        'a1': {'S2': [1, 0]}\n",
    "    },\n",
    "    'S1': {\n",
    "        'a0': {'S0': [0.7, 5], 'S2': [0.2, 0], 'S1': [0.1, 0]},\n",
    "        'a1': {'S1': [0.95, 0], 'S2': [0.05, 0]}\n",
    "    },\n",
    "    'S2': {\n",
    "        'a1': {'S0': [0.3, -1], 'S2': [0.4, 0], 'S1': [0.3, 0]},\n",
    "        'a0': {'S0': [0.4, 0], 'S2': [0.6, 0]}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "mdp1_3 = MDP(states1_3, [], transitions1_3)\n",
    "mdp1_3.reset()\n",
    "\n",
    "for i in range(10):\n",
    "    current_state = mdp1_3.current_state\n",
    "    available_actions = mdp1_3.get_available_actions()\n",
    "    action = random.choice(available_actions)\n",
    "    new_state, reward, done = mdp1_3.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(\"Reached a terminal state.\")\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:02:29.699983Z",
     "start_time": "2024-05-15T09:02:29.691698Z"
    }
   },
   "id": "63ba963d7cbfc1a7",
   "execution_count": 225,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assignment 2.1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47bfefb206a1c029"
  },
  {
   "cell_type": "code",
   "source": [
    "states2_1 = [\n",
    "    '1','2','3','4','5'\n",
    "]\n",
    "\n",
    "terminal_states2_1 = ['1','5']\n",
    "\n",
    "# transitions2_1 = {\n",
    "#     '1' : {\n",
    "#         'r' : {'2' : [1, 0]}\n",
    "#     },\n",
    "#     '2' : {\n",
    "#         'l' : {'1' : [1, -1]},\n",
    "#         'r' : {'3' : [1, 0]}\n",
    "#     },\n",
    "#     '3' : {\n",
    "#         'l' : {'2' : [1, 0]},\n",
    "#         'r' : {'4' : [1, 0]}\n",
    "#     },\n",
    "#     '4' : {\n",
    "#         'l' : {'3' : [1, 0]},\n",
    "#         'r' : {'5' : [1, 1]}\n",
    "#     },\n",
    "#     '5' : {\n",
    "#         'l' : {'4' : [1, 0]}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "def create_transitions(num_states):\n",
    "    transitions = {}\n",
    "    for state in range(1, num_states + 1):\n",
    "        state_str = str(state)\n",
    "        transitions[state_str] = {}\n",
    "        if state < num_states:\n",
    "            transitions[state_str]['r'] = {str(state + 1): [1, 1 if state == num_states - 1 else 0]}\n",
    "        if state > 1:\n",
    "            transitions[state_str]['l'] = {str(state - 1): [1, -1 if state == 2 else 0]}\n",
    "    return transitions\n",
    "\n",
    "num_states = 5\n",
    "transitions2_1 = create_transitions(num_states)\n",
    "\n",
    "mdp2_1 = MDP(states2_1, terminal_states2_1, transitions2_1, slippery_factor=0.6, is_slippery=True, cost_of_living=0.1)\n",
    "mdp2_1.reset()\n",
    "\n",
    "while True:\n",
    "    current_state = mdp2_1.current_state\n",
    "    available_actions = mdp2_1.get_available_actions()\n",
    "    action = random.choice(available_actions)\n",
    "    print(f\"Chosen action:\", action)\n",
    "    new_state, reward, done = mdp2_1.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(\"Reached a terminal state.\")\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T06:51:08.996368Z",
     "start_time": "2024-05-15T06:51:08.977934Z"
    }
   },
   "id": "d11336c7d219e05a",
   "execution_count": 174,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assignment 2.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9a7340ad428572f"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def create_states(h, w):\n",
    "    states = []\n",
    "    for i in range(h):\n",
    "        for j in range(1, w + 1):\n",
    "            states.append(str(j + w * i))\n",
    "    return states\n",
    "\n",
    "def create_transitions(h,w):\n",
    "    transitions = {}\n",
    "    for i in range(h):\n",
    "        for j in range(1, w + 1):\n",
    "            state_str = str(j + w * i)\n",
    "            transitions[state_str] = {}\n",
    "            if i != 0:\n",
    "                transitions[state_str]['u'] = {str(j + w * (i-1) ): [1, 0]}\n",
    "            if i != h - 1:\n",
    "                reward = 1 if j == w and i == h - 2 else -1 if j != 1 and i == h - 2 else 0\n",
    "                transitions[state_str]['d'] = {str(j + w * (i + 1) ): [1, reward]}\n",
    "            if j != 1:\n",
    "                reward = -1 if j != 2 and i == h - 1 else 0\n",
    "                transitions[state_str]['l'] = {str((j - 1) + w * i ): [1, reward]}\n",
    "            if j != w:\n",
    "                reward = 1 if j == w - 1 and i == h - 1 else -1\n",
    "                transitions[state_str]['r'] = {str((j + 1) + w * i ): [1, reward]}\n",
    "\n",
    "    return transitions\n",
    "\n",
    "\n",
    "h = 3\n",
    "w = 5\n",
    "states2_2 = create_states(h, w)\n",
    "current_state2_2 = '1'\n",
    "terminal_states2_2 = [states2_2[-1]]\n",
    "transitions2_2 = create_transitions(h, w)\n",
    "\n",
    "\n",
    "mdp2_2 = MDP(states2_2, terminal_states2_2,transitions2_2, current_state=current_state2_2, is_slippery=True, slippery_factor = 0.5, cost_of_living = 0.01)\n",
    "\n",
    "for i in range(50):\n",
    "    current_state = mdp2_2.current_state\n",
    "    available_actions = mdp2_2.get_available_actions()\n",
    "    action = random.choice(available_actions)\n",
    "    print(\"Actions chosen:\", action)\n",
    "    new_state, reward, done = mdp2_2.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(\"Reached a terminal state.\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:09:29.005671Z",
     "start_time": "2024-05-15T08:09:28.975687Z"
    }
   },
   "id": "6a0414a1a833ccfb",
   "execution_count": 207,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assignment 2.4\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9593c48fc0aa1a"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def create_states():\n",
    "    states = []\n",
    "    for i in range(1,6):\n",
    "        if i != 5:\n",
    "            states.append(str((i,0)))\n",
    "        states.append(str((i,1)))\n",
    "    states.append(str((6,1)))\n",
    "    return states\n",
    "\n",
    "\n",
    "def create_transitions(states):\n",
    "    transitions = {}\n",
    "    for state in states:\n",
    "        transitions[state] = {}\n",
    "        position = ast.literal_eval(state)[0]\n",
    "        key = ast.literal_eval(state)[1]\n",
    "\n",
    "        if 1 < position < 4:\n",
    "            reward_left = -1 if position == 2 else 0\n",
    "            transitions[state]['l'] = {str((position-1, key)) : [1, reward_left]}\n",
    "            transitions[state]['r'] = {str((position+1, key)) : [1, 0]}\n",
    "\n",
    "        if position == 3:\n",
    "            transitions[state]['u'] = {'(6, 1)' : [1, 0]}\n",
    "\n",
    "        if position == 6:\n",
    "            transitions[state]['d'] = {'(3, 1)' : [1, 0]} # good idea to add small reward to this step\n",
    "\n",
    "        if position == 4:\n",
    "            transitions[state]['l'] = {str((position-1, key)) : [1, 0]}\n",
    "            if key == 1:\n",
    "                transitions[state]['r'] = {'(5, 1)' : [1, 1]}\n",
    "\n",
    "\n",
    "    return transitions\n",
    "\n",
    "\n",
    "states2_4 = create_states()\n",
    "\n",
    "terminal_states2_4 = ['(1, 0)',\n",
    "                      '(1, 1)',\n",
    "                      '(5, 1']\n",
    "\n",
    "initial_state2_4 = '(3, 0)'\n",
    "\n",
    "transitions2_4 = create_transitions(states2_4)\n",
    "\n",
    "mdp2_4 = MDP(states2_4, terminal_states2_4, transitions2_4, current_state=initial_state2_4, slippery_factor=0.3, is_slippery=True, cost_of_living=0.01)\n",
    "\n",
    "for i in range(50):\n",
    "    current_state = mdp2_4.current_state\n",
    "    available_actions = mdp2_4.get_available_actions()\n",
    "    action = random.choice(available_actions)\n",
    "    print(\"Actions chosen:\", action)\n",
    "    new_state, reward, done = mdp2_4.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(\"Reached a terminal state.\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T12:57:13.119641Z",
     "start_time": "2024-05-15T12:57:13.090328Z"
    }
   },
   "id": "ef25c9c1749875f5",
   "execution_count": 243,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generic QAgent\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12366cb1fda44491"
  },
  {
   "cell_type": "code",
   "source": [
    "class QAgent:\n",
    "    def __init__(self, mdp):\n",
    "        self.mdp = mdp\n",
    "        self.q_table = {state: {action: 0 for action in mdp.actions[state]} for state in mdp.states}\n",
    "\n",
    "    def train(self,\n",
    "              episodes=400,\n",
    "              learning_rate=0.1,\n",
    "              discount_factor=0.9,\n",
    "              cost_of_living=0.01):\n",
    "\n",
    "        env = self.mdp\n",
    "        \n",
    "        self.q_table = {state: {action: 0 for action in env.actions[state]} for state in env.states}\n",
    "    \n",
    "        epsilon = 1\n",
    "        epsilon_decay = 1/(episodes * 0.9)\n",
    "        random_number_generator = np.random.default_rng()\n",
    "        rewards_per_episode = np.zeros(episodes)\n",
    "        time_rewards_per_episode = np.zeros(episodes)\n",
    "        steps_per_episode = []\n",
    "    \n",
    "        for i in range(episodes):\n",
    "            state = env.reset()\n",
    "    \n",
    "            for step in range(20):\n",
    "                if random_number_generator.random() < epsilon:\n",
    "                    action = random.choice(env.get_available_actions())\n",
    "                else:\n",
    "                    action = max(self.q_table[state], key=self.q_table[state].get)\n",
    "    \n",
    "                new_state, reward, terminated = env.step(action)\n",
    "    \n",
    "                # if terminated & (reward == 0):\n",
    "                #     reward = reward - 1\n",
    "\n",
    "\n",
    "                best_next_action = max(self.q_table[new_state], key=self.q_table[new_state].get)\n",
    "\n",
    "                target = reward + discount_factor * self.q_table[new_state][best_next_action]\n",
    "\n",
    "                td_error = target - self.q_table[state][action]\n",
    "                \n",
    "                self.q_table[state][action] += learning_rate * td_error\n",
    "    \n",
    "                state = new_state\n",
    "    \n",
    "                if terminated:\n",
    "                    break\n",
    "    \n",
    "    \n",
    "            epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "            if epsilon == 0:\n",
    "                learning_rate = learning_rate * 0.1\n",
    "\n",
    "        \n",
    "    def run(self, episodes = 1):\n",
    "\n",
    "        env = self.mdp\n",
    "        \n",
    "        total_reward = 0\n",
    "    \n",
    "        for i in range(episodes):\n",
    "            state = env.reset()\n",
    "        \n",
    "            for i in range(20):\n",
    "                action = max(self.q_table[state], key=self.q_table[state].get)\n",
    "        \n",
    "                new_state, reward, terminated = env.step(action)\n",
    "                \n",
    "                total_reward += reward\n",
    "                \n",
    "                print(f\"{state} -> {action} -> {new_state} | Reward: {reward}\")\n",
    "                \n",
    "                state = new_state\n",
    "\n",
    "            return total_reward\n",
    "\n",
    "\n",
    "    def evaluate_QAgent(self, episodes = 1):\n",
    "        env = self.mdp\n",
    "        total_reward = 0\n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()\n",
    "\n",
    "            for i in range(20):\n",
    "                action = max(self.q_table[state], key=self.q_table[state].get)\n",
    "                new_state, reward, terminated = env.step(action)\n",
    "                total_reward += reward\n",
    "                state = new_state\n",
    "\n",
    "            return total_reward   \n",
    "        \n",
    "\n",
    "    def run_random_agent(self, episodes=1):\n",
    "        total_reward = 0\n",
    "        for _ in range(episodes):\n",
    "            state = self.mdp.reset()\n",
    "\n",
    "            for i in range(20):\n",
    "                action = random.choice(list(self.mdp.actions[state]))\n",
    "                state, reward, terminated = self.mdp.step(action)\n",
    "                total_reward += reward\n",
    "                \n",
    "        return total_reward\n",
    "\n",
    "\n",
    "    def compare_agents(self, episodes=100):\n",
    "        q_agent_rewards = 0\n",
    "        random_agent_rewards = 0\n",
    "        for _ in range(episodes):\n",
    "            q_agent_rewards += self.evaluate_QAgent(1)\n",
    "            random_agent_rewards += self.run_random_agent(1)\n",
    "\n",
    "        print(f\"Q-Agent Total Rewards over {episodes} episodes: {q_agent_rewards}\")\n",
    "        print(f\"Random Agent Total Rewards over {episodes} episodes: {random_agent_rewards}\")\n",
    "    \n",
    "    \n",
    "agent = QAgent(mdp1_3)\n",
    "\n",
    "agent.train(episodes=1000)\n",
    "\n",
    "agent.run(episodes=1)\n",
    "\n",
    "agent.compare_agents(episodes=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:00:13.063333Z",
     "start_time": "2024-05-14T13:00:12.935948Z"
    }
   },
   "id": "2d3ef95855098bc9",
   "execution_count": 112,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T11:19:23.631761Z",
     "start_time": "2024-05-14T11:19:23.628441Z"
    }
   },
   "id": "bd21079a15aec613",
   "execution_count": 93,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
